# set the log level for the node
logLevel: "warn"

# override the fullname
fullnameOverride: null
nameOverride: null

# provider node moniker, will default to the fullname
moniker: null

# chain id of lava
chainId: "lava-testnet-2"

# REQUIRED: The url for a lava RPC node
## example 
# rpcNodeUrl: "https://public-rpc-testnet2.lavanet.xyz:443"
rpcNodeUrl: null


# information about the private key to use for the node
key:
  # will default to the moniker 
  name: "" 

  # REQUIRED: the kubernetes secret name containing the private key
  secretName: null

  # REQUIRED: the key in the kubernetes secret to use
  secretKey: null

  # REQUIRED: the kubernetes secret that contains the password for the private key
  passwordSecretName: null

  # REQUIRED: the key in the kubernetes secret that contains the password for the private key
  passwordSecretKey: null

# REQUIRED: the endpoint the node will expose, this is the endpoint that the node will listen on
# note: this should match your ingress config
## example
# endpoint: lava-provider.example.com
endpoint: null

# REQUIRED: the chain ids for the chains the node will serve
## example
# supportedChainIds: ["ETH1", "COS3"]
supportedChainIds: null


# Set your geolocation
## Geolocation codes
#  USC = 1; // US-Center
#  EU = 2; // Europe
#  USE = 4; // US-East
#  USW = 8; // US-West
#  AF = 16; // Africa
#  AS = 32; // Asia
#  AU = 64;  // (Australia, includes NZ)
#  GL = 65535; // Global
geolocation: "1"

# setup ingress for the node
# example:
# ingress:
#  enabled: true
#  tls:
#    - secretName: lava-provider-tls
#      hosts:
#        - lava-provider.example.com
#  rules:
#    - host: lava-provider.example.com
#      http:
#        paths:
#          - path: /
#            backend:
#              serviceName: lava-provider
#              servicePort: 5000
#  annotations: {}
ingress:
  enabled: true
  className: "nginx"
  tls: []
  rules: []
  annotations: {}

# config for the node
## example
# configYaml: |
#   endpoints:
#     - api-interface: tendermintrpc
#       chain-id: LAV1
#       network-address:
#         address: 0.0.0.0:2224
#         disable-tls: true
#       node-urls:
#         - url: ws://127.0.0.1:26657/websocket
#         - url: http://127.0.0.1:26657
#     - api-interface: grpc
#       chain-id: LAV1
#       network-address:
#         address: 0.0.0.0:2224
#         disable-tls: true
#       node-urls: 
#         url: 127.0.0.1:9090
#     - api-interface: rest
#       chain-id: LAV1
#       network-address:
#         address: 0.0.0.0:2224
#         disable-tls: true
#       node-urls: 
#         url: http://127.0.0.1:1317

# note: This will create a new configMap. 
# If you want to use an existing configMap, or secret use `extraSecretMounts` or `extraConfigMounts` 
# and set `configFilePath`
configYaml: null

# the path to the config file
# If you are using `extraConfigMounts` or `extraSecretMounts`, provide the path to the config file
## example:
# configFilePath: /data/node-config.toml
configFilePath: null

# add custom environment variables to the node using secret of configs
envFrom: []

# add custom environment variables to the node
env: []

# image to deploy
image:
  repository: us-central1-docker.pkg.dev/lavanet-public/images/lavad
  pullPolicy: IfNotPresent
  tag: latest

# port to expose the node on
port:
  name: default
  number: 2224
  protocol: TCP

# set service account name
serviceAccountName: null

# service settings
service:
  enabled: true
  name: null
  type: ClusterIP
  annotations: {}
  # override .Values.port with these values
  ports: null

# mount secrets as files, useful for mounting key file
extraSecretMounts: []
  # - name: node-private-key
  #   mountPath: /data
  #   subPath: /keychain/node-private-key
  #   secretName: node-private-key
  #   readOnly: true

# mount config as files, useful for mounting the config file
extraConfigMounts: []
  # - name: node-config
  #   mountPath: /data
  #   subPath: /data/node-config.toml
  #   configName: node-config
  #   readOnly: true

# setup pvc for the node
persistentVolume:
  ## If true, will create/use a Persistent Volume Claim
  ## If false, use emptyDir
  enabled: true

  ## Must match those of existing PV or dynamic provisioner
  ## Ref: http://kubernetes.io/docs/user-guide/persistent-volumes/
  accessModes:
    - ReadWriteOnce

  ## Persistent Volume labels
  labels: {}

  ## Persistent Volume annotations
  annotations: {}

  ## Persistent Volume existing claim name
  ## Requires persistentVolume.enabled: true
  ## If defined, PVC must be created manually before volume will be bound
  existingClaim: ""

  ## server data Persistent Volume mount root path
  mountPath: /data

  ## data Persistent Volume size
  size: 10Gi

  ## Persistent Volume Storage Class
  ## If defined, storageClassName: <storageClass>
  ## If set to "-", storageClassName: "", which disables dynamic provisioning
  ## If undefined (the default) or set to null, no storageClassName spec is
  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
  ##   GKE, AWS & OpenStack)
  storageClass: null

  ## Subdirectory of data Persistent Volume to mount
  ## Useful if the volume's root directory is not empty
  subPath: ""

  ## Persistent Volume Claim Selector
  ## Useful if Persistent Volumes have been provisioned in advance
  ## Ref: https://kubernetes.io/docs/concepts/storage/persistent-volumes/#selector
  selector: null
  ## ex: 
  # selector:
  #  matchLabels:
  #    release: "stable"
  #  matchExpressions:
  #    - { key: environment, operator: In, values: [ dev ] }

  ## Persistent Volume Name
  ## Useful if Persistent Volumes have been provisioned in advance and you want to use a specific one
  ##
  volumeName: null
  # volumeName: ""

  volumeBindingMode: null

  emptyDir:
    ## emptyDir volume size limit
    sizeLimit: ""

# resource limits for the node
resources:
  requests:
    cpu: "250m"
    memory: 250Mi
  limits:
    memory: "2Gi"

# override the start command to start the provider
command: null

# enable default readiness, using `endpoint` and `supportedChainIds`
defaultReadinessProbe:
  enabled: true
  initialDelaySeconds: 30
  periodSeconds: 10
  timeoutSeconds: 5
  successThreshold: 1
  failureThreshold: 10

# enable default readiness, using `endpoint` and `supportedChainIds`
defaultLivenessProbe:
  enabled: true
  initialDelaySeconds: 60
  periodSeconds: 10
  timeoutSeconds: 5
  successThreshold: 1
  failureThreshold: 3

# use a custom readiness probe
customReadinessProbe:
  enabled: false
  # httpGet:
  #   path: /health
  #   port: 5000
  # initialDelaySeconds: 30
  # periodSeconds: 10
  # timeoutSeconds: 5
  # successThreshold: 1
  # failureThreshold: 3

# use a custom liveness probe
customLivenessProbe:
  enabled: false
  # httpGet:
  #   path: /health
  #   port: 5000
  # initialDelaySeconds: 30
  # periodSeconds: 10
  # timeoutSeconds: 5
  # successThreshold: 1
  # failureThreshold: 3

imagePullSecrets: []
nodeSelector: {}
tolerations: []
affinity: {}
podAnnotations: {}
podSecurityContext: {}
securityContext: {}
